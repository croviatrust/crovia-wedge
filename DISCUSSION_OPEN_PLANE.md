## When no AI training evidence is published

This repository contains a GitHub Action that records a single observable condition:

**whether publicly auditable AI training evidence is present — or absent — at a given time.**

No assumptions are made.
No intent is inferred.
No compliance score is produced.

When evidence is present, nothing happens.
When evidence is absent, that absence becomes observable.

This is not an accusation.
It is not a claim.
It is a record of what was publicly auditable at execution time.

The Action produces:
- a neutral verdict
- an optional evidence pointer
- an append-only local trace

Nothing more.

The question this raises is simple:

> What happens when absence itself becomes observable?

This discussion exists only to document that question.
